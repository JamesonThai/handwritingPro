{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nityamshrestha/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User image import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.ImageOps\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "def img_bw(argv, mode = True):\n",
    "    \"\"\"\n",
    "    This function returns the pixel values.\n",
    "    The imput is a png file location.\n",
    "    \"\"\"\n",
    "    im = Image.open(argv).convert('L')    \n",
    "    im = im.resize((28, 28), Image.ANTIALIAS)\n",
    "#     im = im.reshape(28, 28)\n",
    "    if(mode):\n",
    "        im = PIL.ImageOps.invert(im)\n",
    "    return list(im.getdata())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing my images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic1 = [img_bw('./pure_image/mark000.png'), \n",
    "        img_bw('./pure_image/mark001.png'),\n",
    "       img_bw('./pure_image/mark002.png'), \n",
    "        img_bw('./pure_image/mark003.png'),\n",
    "       img_bw('./pure_image/mark004.png'), \n",
    "        img_bw('./pure_image/mark005.png'),\n",
    "       img_bw('./pure_image/mark006.png'), \n",
    "        img_bw('./pure_image/mark007.png'),\n",
    "       img_bw('./pure_image/mark008.png'), \n",
    "        img_bw('./pure_image/mark009.png')]#file path here\n",
    "pic1 = np.array(pic1)\n",
    "pic1 = pic1.astype(np.float32)\n",
    "pic1 = pic1.reshape(pic1.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "pic1 = pic1.astype('float32')\n",
    "pic1 /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic2 = [img_bw('./pure_image/00.png'), \n",
    "        img_bw('./pure_image/01.png'),\n",
    "       img_bw('./pure_image/02.png'), \n",
    "        img_bw('./pure_image/03.png'),\n",
    "       img_bw('./pure_image/04.png'), \n",
    "        img_bw('./pure_image/05.png'),\n",
    "       img_bw('./pure_image/06.png'), \n",
    "        img_bw('./pure_image/07.png'),\n",
    "       img_bw('./pure_image/08.png'), \n",
    "        img_bw('./pure_image/09.png')]#file path here\n",
    "pic2 = np.array(pic2)\n",
    "pic2 = pic2.astype(np.float32)\n",
    "\n",
    "pic2 = pic2.reshape(pic2.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "pic2 = pic2.astype('float32')\n",
    "pic2 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic3 = [img_bw('./pure_image/twist0.png'), \n",
    "        img_bw('./pure_image/twist1.png'),\n",
    "       img_bw('./pure_image/twist2.png'), \n",
    "        img_bw('./pure_image/twist3.png'),\n",
    "       img_bw('./pure_image/twist4.png'), \n",
    "        img_bw('./pure_image/twist5.png'),\n",
    "       img_bw('./pure_image/twist6.png'), \n",
    "        img_bw('./pure_image/twist7.png'),\n",
    "       img_bw('./pure_image/twist8.png'), \n",
    "        img_bw('./pure_image/twist9.png')]#file path here\n",
    "pic3 = np.array(pic3)\n",
    "pic3 = pic3.astype(np.float32)\n",
    "\n",
    "pic3 = pic3.reshape(pic3.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "pic3 = pic3.astype('float32')\n",
    "pic3 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=8,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saved Files:\n",
    "OG(12) = model_og.h5 --> Done\n",
    "\n",
    "        \n",
    "\n",
    "OG(12) + Shifted = model_og_shifted.h5\n",
    "\n",
    "OG(12) + Shifted + fliped = model_og_shift_flip.h5\n",
    "\n",
    "\n",
    "model_og_shift_flip.h5 + OG(16) = model_og_aug_16.h5\n",
    "\n",
    "Merged Dataset:\n",
    "\n",
    "    OG + shifted(og/2) + flipped(og/2) = model_merged.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = myModel.to_json()\n",
    "\n",
    "with open(\"model_json_shifted_rots.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "myModel.save_weights(\"model_og_shifted_rots.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nityamshrestha/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model_json.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "myModel = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "myModel.load_weights(\"model_og.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nityamshrestha/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2857: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/nityamshrestha/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "myModel.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0274912404745799\n",
      "Test accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "score = myModel.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = myModel.predict_classes(pic1)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = myModel.predict_classes(pic2)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = myModel.predict_classes(pic3)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot \n",
    "import PIL.ImageOps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 60000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Shifted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAEICAYAAADm98d9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzt3Xu0FNWV+PHvDmJQ0AAiyPAQUURRoygaJkRlFCIaI2KMQhQhQ/CJAWMiojG+MOLwUzE+lsPIS38EidFEfAWN6Kgk8vKFiAJRQAR5KYIIIrrnj+5T1X25fW93V3dVV/X+rHXXra6q7t70puueqjrnbFFVjDHGFOdbUQdgjDFxZgdRY4wJwA6ixhgTgB1EjTEmADuIGmNMAHYQNcaYAOwgaowxAST+ICoin9f4+VpE7o46LhOciLwoItszcvte1DGZ0hCR/iKyWES2isi/ROT4qGPKZbeoAyg3VW3ilkWkMbAWeCS6iEyJDVPVB6IOwpSOiPQGbgPOBeYCraONqG6JP4jWcDawDng56kCMMTndCNykqq+mH38UZTD1SfzpfA2DgAfVxromya0iskFEZotIz6iDMcGISAOgG7CviCwTkVUico+I7BF1bLlUzUFURNoDJwJToo7FlMxIoCPQBhgPPCEiB0YbkgmoFdCQ1Fnj8cBRQFfgt1EGVZeqOYgCFwCvqOoHUQdiSkNV56jqFlX9UlWnALOB06KOywSyLf37blVdo6obgDuo4LxW20HUWqHJpoBEHYQpnqp+CqwilctYqIqDqIh8n9Qpn92VTwgRaSoip4hIIxHZTUTOA04AZkYdmwlsEnC5iLQUkWbACODJiGPKqVruzg8CHlPVLVEHYkqmITAaOAT4GngXOFNVra9o/N0MtACWANuBPwG3RBpRHcRuVBtjTPGq4nTeGGPKxQ6ixhgTQKCDqIj0EZH30p1iry5VUCZaltfkstyWXtHXRNMjC5YAvUl1SZgHDFDVd0oXngmb5TW5LLflEeTu/HHAMlV9H0BEHgb6AjkTIiLVfhdrg6ruG3UQ9bC8Fi4OeYUCcxtGXhs1agTAYYcdtsu2LVtSnWmWLFlS7jByySuvQQ6ibYAPMx6vAr4X4PWqwYqoA8iD5bVwccgrVGBuDzroIADmzZu3y7aXXnoJgJ49e4YZUqa88hrkIFrbyJBd/nKJyIXAhQHex4TL8ppc9eY27Lz++Mc/3mXdjh07APj444/DCiOQIAfRVUC7jMdtgdU1d1LV8aQmh7DTvniwvCZXvbm1vBYuyN35eUAnETlARHYH+gMzShOWiZDlNbkst2VQdEtUVXeKyDBSY5UbABNVdVHJIjORsLwmVyXktmHDhgBcccUVAFx44a5XDm644QYAxowZE1pcQQQaO6+qTwNPlygWUyEsr8lluS29apmAxBhTAdq0aQPU3cp88803wwqnJGzYpzHGBGAtUWNMWbnroAAXX3xxrfu8//773vLrr79e9phKyVqixhgTQFW0RPv27QtA+/btATjhhBO8bWeddVatz/nWt/y/L2+//TYAY8eOBeDBBx8sS5zGJNGRRx7pLV911VW17rNokd9JIJ9O9s2bNwfg4IMPBuCyyy7zti1fvhyACRMmZD0uF2uJGmNMAHYQNcaYAGJ5Or/vvv7EKt26dQP80/ITTzwRgMwp/lq3bg3AnnvuCYCIP4Q411SA33zzjbd86KGHAvDf//3fuzznoYceKvJfYUyyuRtK1157bc593Kn20KFD83rNffbZB4A//vGPAPTu3TvnvoMGDQKyZ4hyM0OVkrVEjTEmgIppiTZt2hTwb/pcdNFFOfdt0aKFt3zMMcdkbXOtzLomm960aZO3vHXr1qxt7nGzZs12eT/3l/U73/lOztc2xqQMGzYM8G/s1mbhwoUArFu3Lq/XvO+++4C6W6BO27ZtAejcubO3bv78+Xm9TyGsJWqMMQFUTEt04MCBANx5550lf+3169cDcMstqdLVb731lrdtxYrseVfd48svv9xbV46YjEmq3XZLHVbc/Yna3HTTTQDcfffd9b7eeeed5y2fdtppBcczY4Y/UVWfPn2A7GNAUNYSNcaYAOwgaowxAdR7Oi8iE4HTgXWqenh6XXNgOtABWA6co6qfli/MbJkjhj777LOsbW6ewqDGjRvnLRdbEbWSVWJeTWlEndujjjoKgDPOOCPnPv/6178A2LhxY8593E3j+++/31vXuHHjWvf98EO/dNSGDRsA6Nq1KwD77beft+1nP/sZEP7p/GSgT411VwPPq2on4Pn0YxMvk7G8JtVkLLehqbclqqoviUiHGqv7Aj3Ty1OAF4GRQQJxrcunn65/vtiVK1d6y1999VWQt61aYeXVhC+K3DZo0MBbvu6663Lu9/e//x2AJ554ot7XbNKkCZC79Qn+seD000/31n300UeAX2rZddAvl2LvzrdS1TUAqrpGRFrm2tGqQsaK5TW58sqt5bVwZe/ilG/1QHdts+Y1zrBlDimtafXqVGHEfP6KJp1VhUymYvPqujVB7WWQnenTpwPZA16K4a6Buhaom2kN/Fr2mTGVU7F359eKSGuA9O/8hhuYSmd5TS7LbZkUe6ieAQwCxqR/P16yiCJW12QJbkhozQ76CZLYvBbKDUPu2LEj4F9X++EPf+jt4zpuH3HEESFHV5SKyK27cx+UuwPfvXt3IHsioHbt2gHhDc+utyUqItOAfwKdRWSViAwhlYjeIrIU6J1+bGLE8ppclttw5XN3fkCOTSeXOBYTIstrclluw1UxY+ejNmTIEMAfM59ZHuSDDz4AoF+/fuEHZkpijz32ALLHYbvT8W3btgH+3LTgd69xJX5NaVxyySWAf9Pn9ttvB2DZsmXePu5m0UknnZTzdVxH+vHjx+fcp7YZ3RYsWFBM2HWyYZ/GGBOAtUTT3Mz47q9W5sz2rojWu+++G35gpiiNGjUC4Oc//zngn2EccsghBb2Omwl91apVAMycOdPb5lqwBnbs2OEtuxnZaqv64M7w3HzB559//i7Pd2cBmaWWi/Hmm28CMGvWLG9d5oxOpWItUWOMCaDqW6LuOljNGfIzudpKJj7cRDRuDtna7Ny5E4B33nkHgLlz53rbXKfwxYsXA/5AC1O7zOuOrv6R636UWc64Jjeks66hnYW6+OKLAZgyZQoAX375ZcleuzbWEjXGmADsIGqMMQFU/em8u8CdWfwO4KWXXvKWX3755VBjMsFlziGZKfP0ftq0aYB/Om9Kw53ajxgxAvBnbgK4/vrrgeJHLk2cOBHwL6+43D322GPePm5mt7DmAbaWqDHGBCBhztpeKbP9/PKXv/SWcxWhy5wfsYQWqGq3+neLl6jz+u1vfxuA3//+99664cOHA/DJJ58A/ph31+0FStpSsbwmU155tZaoMcYEUFXXRLt06QJkz9RUszUyevToUGMyxXNDOUeNGgX49XPA79Q9dOhQAN54442QozPVwlqixhgTQFW0RI888kjAv4OXeSfetURdXRjXUdhUPtdZ/rvf/S4ArVq12mWf/v37A/5s55lDEdets3mJTXD5zCfaTkReEJHFIrJIRIan1zcXkedEZGn6d7Pyh2tKxfKaTJbX8OVzOr8TuFJVDwW6A5eJSBesBGvcWV6TyfIasoK7OInI48A96Z+e6cqBrYEXVbVzPc8NrcuEu4kEfmG5/fff38XhbXMzNLniWmUu/VGxXWHiktfauHHy11xzjbcuV5nctWvXesu//vWvAZg6dWrQECyvyZRXXgu6JpquZd0VmIOVYE0My2syWV7DkXdLVESaAP8L3KKqj4nIJlVtmrH9U1Wt8zpLGH/Z3E2kZ5991ltXc0jnwoULveVevXoBfuGrMqu4Fktc8pqPzBtLBx54YNa2n/zkJ4Df5Qn8+SqPPfZYILvsboEsr8lUus72ItIQeBSYqqpukKqVYI05y2syWV7DVe/pvKQuIE4AFqvqHRmbKqIEq5uHcNy4cQCcccYZQPY1MdfadpMVuNYnhNYCrTiVntdiZF7vdMuu072bL9bV9gG/JepmUk+CJOa10uVzTbQHMBBYKCJu2Mc1pJLxp3Q51pXAT8sToikTy2syWV5Dlk/J5FcAybHZSrDGlOU1mSyv4Yv9iKXWrVsDfkGy2sqkupl7XDG6aj2FjyNXvsWV0b3hhhvyep4rTXHbbbcBcPzxxwOwefNmbx83s9Orr75aklhNdbKx88YYE0DsW6KuVelmoj/xxBOB7NmYJk2aBJS9I70pg5EjRwKw++67A/7coeAXIDvhhBMAuPHGG71truXpbiw5rmULsGzZsjJEbKqNtUSNMSaA2LdEN23aBMBJJ50UcSSmHB5/PNUTZ/LkyYA/hBdg5cqVAFxwwQVAdvclZ/bs2YA/5+gHH3xQtlhNdbKWqDHGBFCVNZYiVHHDA0shjLx++OGHALRt29ZbV/P/rtsH4JlnngH8a6qfffZZOcOzvCaT1Vgyxphys4OoMcYEEPsbS6Y69OjRA4AhQ4Z461yhuu3btwMwduxYb9uWLVtCjM5UMzuImtjbuHEj9957L+AfWI0JS9g3ltYDW4Ewx126ORT3JnX5YnmRr9OC4HHvr6r7BnyNihNRXjN1IpXbHUChfZgsrzlEmNfOwMaA7xtaXkM9iAKIyPwo7mSKyGigraoOLvL5kcQdFxHmtT9wFvAOcJCqnl/g8y2vdYji8xGRF4H/r6oPBHiN0OK2G0smtkRkb+Am4MqoYzEld6uIbBCR2SLSM+pg6mIHURNnNwMTVPXDevc0cTIS6Ai0AcYDT4jIgXU/JTpRHETHR/CepRDXuMMS6ucjIkcBvYA7A76U5bVuoX8+qjpHVbeo6peqOgWYDZxW4MuEFnfod+dVNZb/aeMad1gi+Hx6Ah2Alek5ZJsADUSki6oene+LWF7rViGfj5J7ounanxBi3Ik/nReR3USkEdCA1JeskYhY1674Gw8cCByV/rkfeAo4JcqgTDAi0lRETnHfUxE5DzgBmBl1bLlUw8Hkt8D1GY/PB24EbogkGlMSqvoF8IV7LCKfA9tVdX10UZkSaAiMBg4BvgbeBc5U1fcijaoOobVERaSPiLwnIstE5Oqw3ldVb1BVqfFzQx1xthORF0RksYgsEpHh6fXNReQ5EVma/l1nze5qElVuM6XznLN7k+W1cFHkVVXXq+qxqrqXqjZV1e6q+lwdMUae11D6iYpIA2AJ0BtYBcwDBqjqO2V/8wKla3K3VtXXRGQvYAFwJjAY+ERVx6T/QzVT1ZERhloR4pJby2thLK/5C6slehywTFXfV9UdwMNA35DeuyCqukZVX0svbwEWk+pq0ReYkt5tCqlEmZjk1vJaMMtrngIdRAto7rcBMvvyrUqvq2gi0gHoCswBWqnqGkglDmgZXWTlVeBpXOxyW615hWR/Z6PKa9EH0XRz/17gVKALMEBEuuTavZZ1FT3hq4g0AR4FRqjq5vr2T4oC8woxy2215hWS/Z2NNK+qWtQP8O/AzIzHo4BRde1LKgnV/LO+2M87rJ9C8pqxf9Sfa9Q/FZ/XIr+zUX+uUf/kldcgXZxqa+5/r+ZOInIhcCFwRID3Soo41GwuNK8mHnmFPHJrec2SV16DXBPNq7mvquM1NZtKvwDvZcJTUF7VZkCKk3pza3ktXJCD6CqgXcbjtsDqXDur6tMB3suEp6C8mlix3JZBkIPoPKCTiBwgIrsD/YEZpQnLRMjymlyW2zIo+pqoqu4UkWGkbhg1ACaq6qKSRWYiYXlNLstteVjd+XBZffJksrwmk9WdN8aYcrODqDHGBFANU+EZYwwAY8eOBeDKK1Nlubp37w7A3Llzi35Na4kaY0wA1hI1xsTWMcccA0D79u29dYMHDwbggAMOAODf/u3fvG1NmzYFcENbOfvsswFriRpjTGTsIGqMMQHY6bwxpiLts88+APzqV7/y1rnT7xUrUnODdOjQAYCWLf3pQvfaa6+s10lXgwVg0aLU2IKBAwcC8NFHHwWO01qixhgTgLVEjTGR23333b3le+65B4Bjjz0WgO9+97u77N+pUyfAv0GUafv27QA8+eSTANx+++3eNteCXbt2bSnCBqwlaowxgVhL1FS9gw46CIAlS5Z466699loAbr311khiqhbumuapp57qrRsyZEjez58/fz4Af/7zn711TzzxBADvvvtuCSKsn7VEjTEmADuIGmNMAPWezovIROB0YJ2qHp5e1xyYDnQAlgPnqOqn5QvTlJrlFbp1S81y5k7/Mru73HbbbZHEVApxyu35558PwM033+ytq2t6Tnf6fs455wCwfPny8gWXp3xaopOBPjXWXQ08r6qdgOfTj028TMbymlSTsdyGpt6WqKq+JCIdaqzuC/RML08BXgRGljCuyE2YMMFb/v73vw/AddddB2RfxI6ras3r/vvv7y0/9dRTAOy5554AXHDBBd62b775JtzASqiSc9uoUSMARowYAUDHjh2B7Nana226s4EXXnjB27ZlyxYAvvrqq/IHm6di7863UtU1AKq6RkRa5trRSrDGiuU1ufLKreW1cGXv4qSq44HxEI9yAw0bNgTg9NNP99btu+++ANx5550AvPzyy962UnbajZO45dUNBcxsbbZo0QKA3/72twD85S9/CT+wClPuvLquTLfcckvOfe677z4ANm/eDPgzLwEceuihAEyaNAmAM844AwivO1Ntir07v1ZEWgOkf68rXUgmQpbX5LLclkmxLdEZwCBgTPr34yWLKCJ77LEH4M8r6Fqfmdq0aQPAz3/+c2/dmDFjQoguNLHKa+vWrQF/dvK6WpLDhg0D4IYbbvDWuWvbmcMCEyyy3I4aNcpbvuSSS+rd310LdWcKbtIQ8CcTadCgAQBz5swBsr+H7prqc889FyTsvNXbEhWRacA/gc4iskpEhpBKRG8RWQr0Tj82MWJ5TS7LbbjyuTs/IMemk0sciwmR5TW5LLfhsrHzaTfddBMAhx12WL371jarjCkvd8Pvhz/8obdu9OjRACxYsACo/XR+6NChANx4440AvPrqq942d4q/Y8eOMkRsnMz5QJs3b17v/u403qntO+lO613XKPd/AeDzzz8H/JtQq1evLjDiwtiwT2OMCcBaomnNmjWLOgRTi7333hvwu8RcdNFF3rZZs2YB2a0Qx83M5M4w1qxZA8B5553n7bN+/foyRGxq+uc//+ktZ3YdzJQ5+/ymTZuynvfll1962x599FHAb10ecsghgD8MFODEE08E/BtUbhb7crGWqDHGBGAt0bRx48YBcO655wLQuHFjb1vN6y+m/Nq2bQvAM888A0Dnzp0BeOCBB7x9Lr300qznfPvb3/aW77rrLsA/w3BldCthwopq079/f2/ZDZ1261zLMrO16romuc72dXFDQsePH++tmzZtGuDXY5oxY4a37ZFHHin8H1APa4kaY0wAdhA1xpgA7HQ+7e233wbgww8/BPwL1rDrafzrr78eXmBVJLNY2R/+8AcAunTpAvinazVP4cG/3PKb3/zGW+fGaLuZmh5++OEyRGzy8cUXX3jLY8eOBeCOO+4ASndz7+uvv/aW27VrB/j/n1zp5XKxlqgxxgRgLdECuJnPp0yZEnEkyZQ5hr1v375Z21yJ3MzCcW+++Sbgd2dyHeozuRZPv379gOxZtz777DMge2y2Ka9PPvkk9Pc866yzvGV3RlPK+WKtJWqMMQFYS7QAs2fPBmDdOptFrBw+/vhjbzmz8zXASSedlPW7Pu75zz//fM59XKvk4osvLihOU9lcN7bjjjsOgF69ennbjjrqKABee+21kr2ftUSNMSYAa4kWwLVETXlkXu/MNcdnZq+JK664AvArRrq5JSG78zXAihUrAPj0U7/ApeuRYcLTo0cPoPTfJXddHPzWpjsb2bBhg7dt6dKlJX1fyG8+0XYi8oKILBaRRSIyPL2+uYg8JyJL079t8HmMWF6TyfIavnxO53cCV6rqoUB34DIR6YKVYI07y2syWV5Dls+kzGsAVyVwi4gsBtpQISVYS8WVmsgsipVklZjXzG4n27dvr3WfxYsXe8vu1N49L/MUfvLkyWWIsPJVYl4zuYKBbqYl1/0oc+z8woULgbq7nn3ve98D/PHx7pIOQMuWqUKmbpBM5s1IV3K5lAq6JpquZd0VmIOVYE0My2syWV7DkfdBVESaAI8CI1R1c80uKLnEpbTuwQcfDMB+++2Xc5/MmxJJEbe8/ud//qe33K1bN8Af0lmtrc/aVGpeXWnjyy+/HPCrC7jHANu2bQNg1apVQPbMWx06dAD8wRe1zazmhm67GcDcTPflklcXJxFpSCohU1X1sfRqK8Eac5bXZLK8hkvqmyNTUn/CpgCfqOqIjPVjgY2qOkZErgaaq+pV9bxWxbZE3TUaNz9hbdx8lV999VWxb7NAVbsV++RSilteO3bsCMDTTz/trXNzvv7oRz8C4K233ip3GLlYXgvUvn17AGbOnAn488VCfvP21pzj17U+wf8uu25tAeSV13xO53sAA4GFIvJGet01pEqu/ildjnUl8NNiIzWRsLwmk+U1ZPncnX8FyHVBxUqwxpTlNZksr+GzEUtp3bt3jzoEUwt3CcUVHTvggAO8bW7Me4Sn8aZIK1euBODkk1PH9cz5C9z8n25dZqG6jRs3AjB16lQAXnzxRQBefvllb5+tW7eWKera2dh5Y4wJwFqiaW68bW3cX81SzkFo8uNmsnedsjO7MU2aNCmKkEwJudLHv/vd73bZdtlll4UdTlGsJWqMMQFYSzQProRrZh0XEw43J6T77KdPnx5lOMbswlqixhgTgLVETUVyna9PP/10AGbNmgXAs88+G1lMxtTGWqLGGBOAHUSNMSaAqj+db9SoEZA9dremI444AoBvfSv1N8e6OpXfzp07Af+znjt3bpThGJOTtUSNMSaAemdxKumbiawHtgIb6tu3xA4iVTZhBdAAODgdQyHTgbUgeNz7q+q+AV+j4kSY10bAl4CmlzsDS4EvCngNy2sOEeb1AFLj/5cDe5L6/r4L1F7uoHah5TXUgyiAiMwPe9qwdImEK1X16fTjscDeqnpRAa8RetxxEvXnIyKdSZW8GK6qfyrgeZbXOoT9+YhIY+BT4HBVXZJe9xDwkarmXRcqzLir5XT+LqC/iOwpIm2AU4G/RRyTKQERuU9EviDVUlkDPF3PU0xlOxj42h1A094EDosonnpVy0H0f0klYTOwCpgP/DXSiExJqOqlwF7A8cBjpE7vTXw1AT6rse4zUjmuSFEcRMfXv0vpiMi3gJmkvmCNSV0raQbcVuBLhRp3DEX2+ajq1+l5NNsClxT4dMtr3cL+fD4H9q6xbm+g0DKdocUd+jXRsIlIC2A90FRVP0uvOxMYraqHRxqcKSkReQDYqqrDo47FFCfjmuhhqro0ve5BYHUh10TDlPjTeVXdAHwAXCIiu4lIU2AQqessJqZEpKWI9BeRJiLSQEROAQYAs6KOzRRPVbeSOmu8SUQai0gPoC/wULSR5Zb4g2jaWUAfUi3SZaS6O10RaUQmKCV16r6KVMvl/5EqD/x4pFGZUrgU2INUF8RpwCWquijakHIL7XReRPqQukveAHhAVceE8sYFEpF2wIPAfsA3wHhVvUtEmgPTgQ6k+q+do6rJK0RfhDjk1vJaOMtrnjGEcRAVkQbAEqA3qZbDPGCAqr5T9jcvULomd2tVfU1E9gIWAGcCg0mVoXUlZ5up6sgIQ60Iccmt5bUwltf8hXU6fxywTFXfV9UdwMOkrnNUHFVdo6qvpZe3AIuBNqTinZLebQqpRJmY5NbyWjDLa54CHURFpI+IvCciy9JH+1zaAB9mPF6VXlfRRKQD0BWYA7RS1TWQShzQMrrIyquAvEIMc1uteYVkf2ejymvRB9F0c/9eUqN/ugADRKRLrt1rWVfRfatEpAnwKKmbFZujjicsBeYVYpbbas0rJPs7G2leVbWoH+DfgZkZj0cBo+ral1QSqvlnfbGfd1g/heQ1Y/+oP9eofyo+r0V+Z6P+XKP+ySuvQeYTra25/72aO4nIhcCFwBEB3ispVkQdQB4KzauJR14hj9xaXrPkldcgB9G8mvuqOh4YLyKnAU8FeD8TjoLyCiAiu2w3Fane3CYhr4cfnhqI2KFDBwCWL1/ubXv77bdL/n5BbiytAtplPG4LrM61s6anoTMVr6C8mlix3JZBkIPoPKCTiBwgIrsD/YEZpQnLRMjymlyW2zIo+nReVXeKyDBSN4waABO1godmmfxYXpMrCbk9+uijATjssNT0or/4xS922adjx44AtGmT6pG1Zs0ab5vb/9NPU4OX3nvvvazHxQhUqC59im6n6QljeU0uy23pVX21T2NMZXFVdS+6KFW9p1evXt62U089FfCr9OajdevW3vJTT2Xf2/7rX1Nzs//qV7/y1mXeiMor3oL2NsYYkyXsap+x7DJRQgs0gUXRLK+W16D23dcvqnnbbamiE4MHDw7r7dm4caO3fOCBBwKwefPmvPJqLVFjjAnArokaYyLj7pYfeeSR3rpSt0BHjx7tLX/5ZXYdw4EDBwJw8MEHe+umT58O+Ndf62MtUWOMCcAOosYYE4CdzpuKdMghhwDQp08fwB8P3apVK2+fH/3oR/W+zrp16wAYNmwYAH/+859LGqcpTJcuqZn3fvnLXwIwdOhQAERqG9afv7/97W/e8jvvpCbfv+aaawD46quvvG01b6Q//niqJNdbb73lrXv++ecLem9riRpjTADWEq3hO9/5DuD/hQK/y8OAAQMAeOWVV8IPrApkDuG7/fbbAWjSpEnWPpktlny657VsmZrQfMyYVI21GTP8oeI7duwoPlhTlIsvvhiACy/Mnm3v888/95afeeYZAH7605/mfB23z3/9138BMG/ePG/bF198kXc833zzTd775mItUWOMCcA629cwadIkAAYNGrTLtq1btwKw1157Ffvy1im7DjNnzvSW3VC/LVu2ADBr1iwA/vGPf3j7uP+7S5cu3eW1OnXqBMAZZ5wBwA9+8AMA7rnnHm+f4cOHlyJssLzW6ZZbbvGWr7rqKgAaNGgAwPz58wEYO3ast88HH3wAwNy5c3d5rT/84Q+1wb5xAAAKUUlEQVQAjBo1CoBt27YFim38+PFA9lmQm7CkTZs21tneGGPKzQ6ixhgTQL03lkRkInA6sE5VD0+vaw5MBzoAy4FzVLX4CflKoHnz5lm/3U0ggKZNm2bte/fdd3vLNWdscTce9thjD2/dOeecU9JYK0El5jXzpo+b59GdCq5du7ao13z11VcBeOmllwBo165dXbsnQqXl1nU1Av8SzObNqYKc7kbTxx9/7O0zZ84cwD+tfvTRR71tI0eOBHYdeVQo13XuzDN3LUf/5JNPFvRa+bREJwN9aqy7GnheVTsBz6cfm3iZjOU1qSZjuQ1NvS1RVX1JRDrUWN0X6JlengK8CIwsYVx1ymwlur9kl156KeB3R6pLZveKHj16AH5n27/85S9Adjcm1xJ179u7d29v23PPPVf4P6ACVGJe77333pK/5ogRI7Ie13YTKmkqMbc1ue/ta6+9BmR/b92M9Ndddx2QfWOqGJnd5I4//ngAHnzwQQD22WcfILur0+uvv17Q6xfbT7SVqq4BUNU1ItIy145WgjVWLK/JlVduLa+FK3tn+1KWYHUtwd/97nfeOneNxHG1UjK7R7huMW4oYV3XS90+d9555y7v7zp6uw751awSS+u6Erngn22cffbZgH8Nrhyt3SQJK691lS7evn07kN3lrRC77ZY6rLluVI888oi37ZRTTqn1Oa5rI8D9999f0PsVe3d+rYi0Bkj/Xlfk65jKYnlNLsttmRTbEp0BDALGpH8/XvfupeEmnMhsfbrWofurNWTIEAA++uijnK9T23Ay18q9+eabgdr/Yo0bNw5I9CQWkeS1EJkDHdwZgfv/0L9/f2+b66Xhhna6Tt4rV64MJc4KVFG5da3D2r5nLmeuI34++vXr5y3/5je/AaB79+71Pm/Dhg1AsDOUeluiIjIN+CfQWURWicgQUonoLSJLgd7pxyZGLK/JZbkNVz535wfk2HRyiWMxIbK8JpflNlyxn8XJdd515VXrOo0/6qijAPjjH//orXOnDosWLQL8mxOZcwq4+Ql///vflyhqk6+2bdsC/gCJrl27etvq6ji/YsUKwL88k3njwITLzV8AcMUVVwDQs2dPABYvXgzAE0884e3jLtm4U/7M+T2vvfZaYNebu5kllN2Npbq4jvwutjfeeCOPf0ntbNinMcYEEPuWqHP00UcDfgskk5tT8sc//jGQ3eHazRuaWbIVsrtXnHbaaaUN1uTt17/+NeC3GPKdT9TdlLAWaPQyW5lu3tBjjjkG8FudtQ2t/slPfpL1u1jvv/++t+w62f/P//wP4LdIg7CWqDHGBBCrluiyZcsAf15PgMaNGwMwdepUwG+RugkswB+meckllwCw33777fLabtiXm6+wZid+E426Jh5xE1Mce+yxALRv397b5lovrhTukiVLyhWiKcALL7wA+MMv3TVSV3sJ/HwW4t133/WWXV0tdy31oYce8rbVnHCoFKwlaowxAdhB1BhjAohleZCTT/a7u9WcRcnNS5hZQnXw4ME5X8ud9g8cOBAobJREEayMRBm5GbgA+vbtC8Ds2bMB//SxTCyvAbnLcuB3fypE5sxLq1evLkVIkGderSVqjDEBxLIlmjnzkvsLtP/++9f7PHdz4fzzz/fWuZaoK4hWZtZiKaODDjrIW3aF7Xbu3An4hepK2ErJZHlNJmuJGmNMucWqi9N//Md/AHDrrbd66/Jpgd51112A33H766+/LkN0JmquCxzAxIkTAX/u2csvvxzwS+0aUyrWEjXGmABi0RK97LLLAH8yiZqz0YPfCsm8Lua4WbStBVo9ag7/Pe+88wBriZrSy2c+0XYi8oKILBaRRSIyPL2+uYg8JyJL07+blT9cUyqW12SyvIYvn9P5ncCVqnoo0B24TES6YCVY487ymkyW15DlMynzGsBVCdwiIouBNpS5BGtmmVNXMnXvvfcGsrsjudKrbkxubV1YXLGyCRMmlCq82As7r65sy0knneStc6fYYahtdq8kiur7Ws0KuiaarmXdFZiDlWBNDMtrMllew5H3QVREmgCPAiNUdXPmvI51KbYEa2ar0bVA3dx/v/jFL7xtzzzzDFD7zSYnwYXlAit3Xlu0aAH48zdmcsXBXEnroNys5+DfhHRnLTfeeGNJ3iMuwv6+VrO8ujiJSENSCZmqqo+lV1sJ1pizvCaT5TVc9bZEJfUnbAKwWFXvyNhU1hKstdXPcS0W1/rM5Gos1Wb79u2lCywhws5rbcOLr7/+egCmTZsGwJNPPlnQa7o5Q8866yzAH4wBsG3bNsA/o/n73/9eYMTxFNX3tZrlczrfAxgILBQRV83pGlLJ+FO6HOtKYNdi7qaSWV6TyfIasnzuzr8C5LqgYiVYY8rymkyW1/DFYsRSXdyNC1dmwHnqqae8ZVc6xIRv8+bNAMydOxeA4447ztvWq1cvwC/fks+MYnUVqsvs+uYKnz377LPFhG1M3mzsvDHGBBCrlqgrOuZm5gH/hpIri+z89a9/DS8wk9OOHTsAGDp0KODfRILs4mTF2LhxIwALFiwA/EEZAK+88kqg1zYmX9YSNcaYACq2JerKnQJ0794dgCOOOCLrd21cB27rYF9Z3ExamddEzz33XABatWoFQL9+/bxtucrmZs4lO378eKB6hnSaymQtUWOMCaBiayw1a+bP1OUqeh599NG77OeqerrrYYsWLQJg06ZNxQdaPlaLJ5ksr8lkNZaMMabc7CBqjDEBVOyNpU8//dRb7tYtcWdKxpiEsJaoMcYEEHZLdAOwNf07bloQPO766zvHk+U1mSyveQj17jyAiMyP453MuMYdlrh+PnGNOyxx/XzCjNtO540xJgA7iBpjTABRHETHR/CepRDXuMMS188nrnGHJa6fT2hxh35N1BhjksRO540xJgA7iBpjTAChHURFpI+IvCciy0Tk6rDet1Ai0k5EXhCRxSKySESGp9c3F5HnRGRp+nez+l6rWsQht5bXwlle84whjGuiItIAWAL0BlYB84ABqvpO2d+8QOma3K1V9TUR2QtYAJwJDAY+UdUx6f9QzVR1ZIShVoS45NbyWhjLa/7CaokeByxT1fdVdQfwMNA3pPcuiKquUdXX0stbgMVAG1LxTknvNoVUokxMcmt5LZjlNU9hHUTbAB9mPF6VXlfRRKQD0BWYA7RS1TWQShzQMvczq0rscmt5zYvlNU9hHURrq4Nd0X2rRKQJ8CgwQlU3Rx1PBYtVbi2vebO85imsg+gqoF3G47bA6pDeu2Ai0pBUQqaq6mPp1WvT11/cdZh1UcVXYWKTW8trQSyveQrrIDoP6CQiB4jI7kB/YEZI710QERFgArBYVe/I2DQDGJReHgQ8HnZsFSoWubW8Fszymm8MYY1YEpHTgHFAA2Ciqt5Sz1MiISI/AF4GFgLfpFdfQ+o6y5+A9sBK4Keq+kkkQVaYOOTW8lo4y2ueMdiwT2OMKZ6NWDLGmADsIGqMMQHYQdQYYwKwg6gxxgRgB1FjjAnADqLGGBOAHUSNMSaA/wOifYRzaQfUdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define data preparation\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift)\n",
    "# fit parameters from data\n",
    "datagen.fit(x_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_train_shift, y_batch in datagen.flow(x_train, y_train, batch_size=batch):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_train_shift[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "        pyplot.title(y_batch[i])\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10e200860>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(X_train_shift[0].reshape(28, 28), cmap=pyplot.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train_shift = X_train_shift.astype('float32')\n",
    "X_test_shift = x_test.astype('float32')\n",
    "\n",
    "X_train_shift /= 255\n",
    "X_test_shift /= 255\n",
    "\n",
    "print('x_train shape:', X_train_shift.shape)\n",
    "print(X_train_shift.shape[0], 'train samples')\n",
    "print(X_test_shift.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_batch_shift = keras.utils.to_categorical(y_batch, num_classes)\n",
    "y_test_shift = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_shift.shape)\n",
    "print(y_batch_shift.shape)\n",
    "print(y_test_shift.shape)\n",
    "print(X_test_shift.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 2.3026 - acc: 0.1116 - val_loss: 2.3014 - val_acc: 0.1135\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 175s 3ms/step - loss: 2.3014 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 155s 3ms/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 154s 3ms/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 154s 3ms/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 216s 4ms/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 649s 11ms/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 367s 6ms/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 172s 3ms/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 156s 3ms/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Test loss: 2.301029739379883\n",
      "Test accuracy: 0.1135\n"
     ]
    }
   ],
   "source": [
    "myModel.fit(X_train_shift, y_batch_shift,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_shift, y_test_shift))\n",
    "score = myModel.evaluate(X_test_shift, y_test_shift, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.05019276161667704\n",
      "Test accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "score = myModel.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Rotated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(rotation_range=180)\n",
    "# fit parameters from data\n",
    "datagen.fit(x_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch_rotation, y_batch in datagen.flow(x_train, y_train, batch_size=batch):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch_rotation[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "        pyplot.title(y_batch[i])\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_batch_rotation.shape)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rot = X_batch_rotation.astype('float32')\n",
    "X_test_shift = x_test.astype('float32')\n",
    "\n",
    "X_train_rot /= 255\n",
    "X_test_shift /= 255\n",
    "\n",
    "print('x_train shape:', X_train_rot.shape)\n",
    "print(X_train_rot.shape[0], 'train samples')\n",
    "print(X_test_shift.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train_rot = keras.utils.to_categorical(y_batch, num_classes)\n",
    "y_test_rot = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.fit(X_train_rot, y_train_rot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_shift, y_test_rot))\n",
    "score = myModel.evaluate(X_test_shift, y_test_rot, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = myModel.evaluate(X_test_shift, y_test_rot, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Flipped Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(x_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch_flip, y_batch in datagen.flow(x_train, y_train, batch_size=batch):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch_flip[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "        pyplot.title(y_batch[i])\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flipped = X_batch_flip.astype('float32')\n",
    "X_test_shift = x_test.astype('float32')\n",
    "\n",
    "X_train_flipped /= 255\n",
    "X_test_shift /= 255\n",
    "\n",
    "print('x_train shape:', X_train_flipped.shape)\n",
    "print(X_train_flipped.shape[0], 'train samples')\n",
    "print(X_test_shift.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train_flip = keras.utils.to_categorical(y_batch, num_classes)\n",
    "y_test_flip = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.fit(X_train_rot, y_train_rot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_shift, y_test_rot))\n",
    "score = myModel.evaluate(X_test_shift, y_test_rot, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Whitend Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train_whitening)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch_whitening, y_batch in datagen.flow(X_train_whitening, y_train, batch_size=batch):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch_whitening[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "        plt.title(y_batch[i])\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_batch_shift = keras.utils.to_categorical(y_batch, num_classes)\n",
    "y_test_shift = keras.utils.to_categorical(y_test, num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
